{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "from keras import applications, optimizers\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import cv2\n",
    "import keras\n",
    "import os, csv\n",
    "import shutil\n",
    "import imgaug as ia\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions the images.\n",
    "img_width, img_height = 512, 384\n",
    "\n",
    "train_data_dir = './dataset/train'\n",
    "test_data_dir = './dataset/test'\n",
    "validation_data_dir = './dataset/validation'\n",
    "original_data_dir = './dataset-resized'\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel():\n",
    "    # build the VGG16 network\n",
    "    base_model = applications.VGG16(weights='imagenet', \n",
    "                                    include_top=False,\n",
    "                                    input_tensor=Input(shape=(img_width, img_height, 3)))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = base_model.output\n",
    "    top_model = Flatten(name=\"Flatten\")(top_model)\n",
    "    top_model = Dense(512, activation='relu')(top_model)\n",
    "    top_model = Dense(256, activation='relu')(top_model)\n",
    "    top_model = Dense(6, activation='softmax')(top_model)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=top_model)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStratifiedData():\n",
    "    # create dataframe with the images filenames\n",
    "    dataset_files = open('./dataset.csv', 'w+')\n",
    "    writer = csv.writer(dataset_files)\n",
    "\n",
    "    writer.writerow(['image','class'])\n",
    "    for path, dirs, files in os.walk(original_data_dir):\n",
    "        for filename in files:\n",
    "            if( filename != '.DS_Store'):\n",
    "                writer.writerow([filename, os.path.basename(path)])\n",
    "\n",
    "    # dataframe containing the filenames of the images and the classes\n",
    "    df = pd.read_csv('./dataset.csv')\n",
    "    df_y = df['class']\n",
    "    df_x = df['image']\n",
    "\n",
    "    skf = StratifiedShuffleSplit(n_splits = 1, test_size=0.2)\n",
    "\n",
    "    for train_index, test_index in skf.split(df_x, df_y):\n",
    "        x_train, x_test = df_x[train_index], df_x[test_index]\n",
    "        y_train, y_test = df_y[train_index], df_y[test_index]\n",
    "\n",
    "        train = pd.concat([x_train, y_train], axis=1)\n",
    "        test = pd.concat([x_test, y_test], axis = 1)\n",
    "        # take 20% of the training data from this fold for validation during training\n",
    "        validation = test.sample(frac = 0.5)\n",
    "\n",
    "        # make sure validation data does not include training data\n",
    "        train = train[~train['image'].isin(list(validation['image']))]\n",
    "\n",
    "        # copy the images according to the fold\n",
    "        copy_images(train, 'train')\n",
    "        copy_images(validation, 'validation')\n",
    "        copy_images(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to copy files according to each fold\n",
    "def copy_images(dataframe, directory):\n",
    "    destination_directory = './dataset/{}'.format(directory)\n",
    "    print('copying {} files to {}...'.format(directory, destination_directory))\n",
    "\n",
    "    # remove all files from previous fold\n",
    "    if os.path.exists(destination_directory):\n",
    "        shutil.rmtree(destination_directory)\n",
    "\n",
    "    # create folder for files from this fold\n",
    "    if not os.path.exists(destination_directory):\n",
    "        os.makedirs(destination_directory)\n",
    "\n",
    "    # create subfolders for each class\n",
    "    for image_class in set(list(dataframe['class'])):\n",
    "        if not os.path.exists(destination_directory + '/' + image_class):\n",
    "            os.makedirs(destination_directory + '/' + image_class)\n",
    "\n",
    "    # copy files for this fold from a directory holding all the files\n",
    "    for i, row in dataframe.iterrows():\n",
    "        try:\n",
    "            # this is the path to all of your images kept together in a separate folder\n",
    "            path_from = '{}/{}/{}'.format(original_data_dir, row['class'],row['image'])\n",
    "            path_to = \"{}/{}\".format(destination_directory, row['class'])\n",
    "            \n",
    "            # move from folder keeping all files to training, test, or validation folder (the \"directory\" argument)\n",
    "            shutil.copy(path_from, path_to)\n",
    "        except Exception as e:\n",
    "            print(\"Error when copying {}: {}\".format(row['image'], str(e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentData():        \n",
    "    # create numpy array with images paths\n",
    "    img_paths = np.array([])\n",
    "    for path, dirs, files in os.walk(train_data_dir):\n",
    "        for filename in files:\n",
    "            if(filename != '.DS_Store'):\n",
    "                path_name = '{}/{}/{}'.format(train_data_dir,os.path.basename(path),filename)\n",
    "                img_paths = np.append(img_paths, path_name)   \n",
    "                \n",
    "    # convert images to numpy arrays\n",
    "    paths_number, = img_paths.shape\n",
    "    \n",
    "    images = np.zeros(shape=(paths_number,img_height,img_width,3),dtype='uint8')\n",
    "    for idx, img_path in enumerate(img_paths):\n",
    "        print('Creating array from ', img_path)\n",
    "        img = cv2.imread(img_path, 1)\n",
    "        im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images[idx] = im_rgb\n",
    "        \n",
    "    # aug configurations\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Affine(scale=(0.8, 1.3), mode=['edge']), # Scale images to a value between 80% and 150%\n",
    "        iaa.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, mode=['edge']), # Translate images by -10 to +10% on x- and y-axis independently\n",
    "        iaa.Affine(rotate=(-25, 25), mode=['edge']), # Rotate images by -45 to 45 degrees\n",
    "        iaa.GaussianBlur(sigma=(0.0, 1.0)), # Blur each image with a gaussian kernel with a sigma of 2.0:\n",
    "        iaa.AdditiveGaussianNoise(scale=(0, 0.01*255)), # Add gaussian noise to an image, sampled once per pixel from a normal distribution N(0, s), where s is sampled per image and varies between 0 and 0.05*255\n",
    "        iaa.Fliplr(0.5), # Flip 50% of all images horizontally\n",
    "        iaa.Flipud(0.5), # Flip 50% of all images vertically\n",
    "        iaa.CropAndPad(percent=(-0.1, 0.1), pad_mode=['edge']) # Crop or pad each side by up to 10 percent relative to its original size\n",
    "    ], random_order=True)\n",
    "\n",
    "    # create augmented images\n",
    "    images_aug = seq.augment_images(images)\n",
    "    \n",
    "    # save augmented images\n",
    "    for i in range(len(img_paths)):\n",
    "        img_dest = '{}_AUG.jpg'.format(img_paths[i][:-4])  \n",
    "        Image.fromarray(images_aug[i]).save(img_dest)\n",
    "        print('Saving ',img_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(batch_size):\n",
    "    train_datagen = ImageDataGenerator()\n",
    "\n",
    "    validation_datagen = ImageDataGenerator()\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    \n",
    "    return [train_generator,validation_generator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fineTuneModel(model, train_generator, validation_generator, epochs, batch_size):\n",
    "    training_samples = 0\n",
    "    validation_samples = 0\n",
    "    \n",
    "    for path, dirs, files in os.walk(train_data_dir):\n",
    "        for filename in files:\n",
    "            training_data += 1 \n",
    "\n",
    "    for path, dirs, files in os.walk(validation_data_dir):\n",
    "        for filename in files:\n",
    "            validation_data += 1 \n",
    "        \n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=training_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_samples // batch_size)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel()\n",
    "train_generator,test_generator = generateData(batch_size)\n",
    "trained_model = fineTuneModel(model,train_generator, test_generator, epochs, batch_size)\n",
    "metrics = getMetrics(trained_model, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying train files to ./dataset/train...\n",
      "copying validation files to ./dataset/validation...\n",
      "copying test files to ./dataset/test...\n"
     ]
    }
   ],
   "source": [
    "createStratifiedData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating array from  ./dataset/train/paper/paper5.jpg\n",
      "Creating array from  ./dataset/train/paper/paper2.jpg\n",
      "Creating array from  ./dataset/train/paper/paper3.jpg\n",
      "Creating array from  ./dataset/train/paper/paper1.jpg\n",
      "Creating array from  ./dataset/train/metal/metal2.jpg\n",
      "Creating array from  ./dataset/train/metal/metal3.jpg\n",
      "Creating array from  ./dataset/train/metal/metal1.jpg\n",
      "Creating array from  ./dataset/train/metal/metal4.jpg\n",
      "Creating array from  ./dataset/train/cardboard/cardboard4.jpg\n",
      "Creating array from  ./dataset/train/cardboard/cardboard6.jpg\n",
      "Creating array from  ./dataset/train/cardboard/cardboard3.jpg\n",
      "Creating array from  ./dataset/train/cardboard/cardboard2.jpg\n",
      "Creating array from  ./dataset/train/trash/trash4.jpg\n",
      "Creating array from  ./dataset/train/trash/trash2.jpg\n",
      "Creating array from  ./dataset/train/trash/trash3.jpg\n",
      "Creating array from  ./dataset/train/trash/trash1.jpg\n",
      "Creating array from  ./dataset/train/glass/glass3.jpg\n",
      "Creating array from  ./dataset/train/glass/glass2.jpg\n",
      "Creating array from  ./dataset/train/glass/glass1.jpg\n",
      "Creating array from  ./dataset/train/glass/glass4.jpg\n",
      "Creating array from  ./dataset/train/plastic/plastic8.jpg\n",
      "Creating array from  ./dataset/train/plastic/plastic9.jpg\n",
      "Creating array from  ./dataset/train/plastic/plastic12.jpg\n",
      "Creating array from  ./dataset/train/plastic/plastic10.jpg\n",
      "Saving  ./augmented/0.jpg\n",
      "Saving  ./augmented/1.jpg\n",
      "Saving  ./augmented/2.jpg\n",
      "Saving  ./augmented/3.jpg\n",
      "Saving  ./augmented/4.jpg\n",
      "Saving  ./augmented/5.jpg\n",
      "Saving  ./augmented/6.jpg\n",
      "Saving  ./augmented/7.jpg\n",
      "Saving  ./augmented/8.jpg\n",
      "Saving  ./augmented/9.jpg\n",
      "Saving  ./augmented/10.jpg\n",
      "Saving  ./augmented/11.jpg\n",
      "Saving  ./augmented/12.jpg\n",
      "Saving  ./augmented/13.jpg\n",
      "Saving  ./augmented/14.jpg\n",
      "Saving  ./augmented/15.jpg\n",
      "Saving  ./augmented/16.jpg\n",
      "Saving  ./augmented/17.jpg\n",
      "Saving  ./augmented/18.jpg\n",
      "Saving  ./augmented/19.jpg\n",
      "Saving  ./augmented/20.jpg\n",
      "Saving  ./augmented/21.jpg\n",
      "Saving  ./augmented/22.jpg\n",
      "Saving  ./augmented/23.jpg\n"
     ]
    }
   ],
   "source": [
    "augmentData()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
